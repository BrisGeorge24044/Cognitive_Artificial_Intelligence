{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPffxMI/0hj1udTl+z6xiN/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BrisGeorge24044/Cognitive_Artificial_Intelligence/blob/main/LeakyRNN_ContextDecisionMaking_sparse_matrices.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MT5ypecXCD4S",
        "outputId": "bf536138-3472-4e37-889d-6e8803765fd5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting neurogym\n",
            "  Downloading neurogym-0.0.2.tar.gz (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from neurogym) (1.26.4)\n",
            "Collecting gym<0.25,>=0.20.0 (from neurogym)\n",
            "  Downloading gym-0.24.1.tar.gz (696 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m696.4/696.4 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from neurogym) (3.8.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym<0.25,>=0.20.0->neurogym) (3.1.0)\n",
            "Requirement already satisfied: gym_notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym<0.25,>=0.20.0->neurogym) (0.0.8)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->neurogym) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->neurogym) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->neurogym) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->neurogym) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->neurogym) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->neurogym) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->neurogym) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->neurogym) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->neurogym) (1.16.0)\n",
            "Building wheels for collected packages: neurogym, gym\n",
            "  Building wheel for neurogym (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for neurogym: filename=neurogym-0.0.2-py3-none-any.whl size=118573 sha256=b58ffc7678955aa38639ec6123603c1aec29b4e7881630e0a5cda17dba16d600\n",
            "  Stored in directory: /root/.cache/pip/wheels/f4/57/a7/66ed4eccf946052534253e4279438b97133b64facca56d4238\n",
            "  Building wheel for gym (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.24.1-py3-none-any.whl size=793128 sha256=b35b8e2d255540f9866af6cf8eec3bad41bd46fe1ace894d1f4403ba80d91741\n",
            "  Stored in directory: /root/.cache/pip/wheels/c4/fb/19/388995b88cb551717a8dff40c889172cd12fadf994216a0a22\n",
            "Successfully built neurogym gym\n",
            "Installing collected packages: gym, neurogym\n",
            "  Attempting uninstall: gym\n",
            "    Found existing installation: gym 0.25.1\n",
            "    Uninstalling gym-0.25.1:\n",
            "      Successfully uninstalled gym-0.25.1\n",
            "Successfully installed gym-0.24.1 neurogym-0.0.2\n",
            "Collecting gym==0.25.1\n",
            "  Using cached gym-0.25.1-py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym==0.25.1) (1.26.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym==0.25.1) (3.1.0)\n",
            "Requirement already satisfied: gym_notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym==0.25.1) (0.0.8)\n",
            "Installing collected packages: gym\n",
            "  Attempting uninstall: gym\n",
            "    Found existing installation: gym 0.24.1\n",
            "    Uninstalling gym-0.24.1:\n",
            "      Successfully uninstalled gym-0.24.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "neurogym 0.0.2 requires gym<0.25,>=0.20.0, but you have gym 0.25.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gym-0.25.1\n"
          ]
        }
      ],
      "source": [
        "! pip install neurogym\n",
        "!pip install gym==0.25.1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import time"
      ],
      "metadata": {
        "id": "2lmmkXvyCbxg"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LeakyRNN Class defines the Leaky RNN and sets parameters."
      ],
      "metadata": {
        "id": "ZM0OqA2_VjD3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LeakyRNN(nn.Module):\n",
        "\n",
        "  # Function creates sparse matrices\n",
        "  def sparse_matrices(self, in_feat, out_feat, sparsity = 0.8):\n",
        "    linear_layer = nn.Linear(in_feat, out_feat)\n",
        "    # Creates a binary mask to apply the sparsity\n",
        "    mask = (torch.rand(out_feat, in_feat) > sparsity).float()\n",
        "    linear_layer.weight.data = linear_layer.weight.data * mask\n",
        "    return linear_layer\n",
        "\n",
        "\n",
        "  def __init__(self, input_size, hidden_size, dt = None):\n",
        "    super().__init__()\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.tau = 100\n",
        "    # Sets alpha as a function of the time step, dt, and the time constant, tau\n",
        "    if dt is None:\n",
        "      alpha = 1\n",
        "    else:\n",
        "      alpha = dt/self.tau\n",
        "    self.alpha = alpha\n",
        "    # Defines sparse layers for the input to hidden and hidden to hidden\n",
        "    # connections\n",
        "    self.input2hidden = self.sparse_matrices(input_size, hidden_size)\n",
        "    self.hidden2hidden = self.sparse_matrices(hidden_size, hidden_size)\n",
        "\n",
        "  # init_hidden function initialises the hidden state as a matrix of zeros\n",
        "  def init_hidden(self, input_shape):\n",
        "    batch_size = input_shape[1]\n",
        "    return torch.zeros(batch_size, self.hidden_size)\n",
        "\n",
        "  # Recurrence function updates the hidden state\n",
        "  def recurrence(self, input, hidden):\n",
        "    # ReLU non-linear activation function is used to calculate the new hidden\n",
        "    # state using the input and recurrent weight matrices\n",
        "    h_new = torch.relu(self.input2hidden(input) + self.hidden2hidden(hidden))\n",
        "    # Leaky integration is applied with alpha deciding how much of the last\n",
        "    # state is retained\n",
        "    h_new = hidden * (1 - self.alpha) + h_new * self.alpha\n",
        "    return h_new\n",
        "\n",
        "  # Forward function - process the sequence for every time step\n",
        "  def forward(self, input, hidden = None):\n",
        "    # If there is no hidden state, then it is initialised here\n",
        "    if hidden is None:\n",
        "      hidden = self.init_hidden(input.shape).to(input.device)\n",
        "\n",
        "      output = []\n",
        "      # Creates a loop for every time step\n",
        "      steps = range(input.size(0))\n",
        "      for i in steps:\n",
        "        # Updates the hidden state using the recurrence function\n",
        "        hidden = self.recurrence(input[i], hidden)\n",
        "        output.append(hidden)\n",
        "\n",
        "      # Stacks all outputs in one dimension\n",
        "      output = torch.stack(output, dim = 0)\n",
        "      return output, hidden"
      ],
      "metadata": {
        "id": "87sXVnkLCdv_"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RNNNet(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size, **kwargs):\n",
        "    super().__init__()\n",
        "\n",
        "    self.rnn = LeakyRNN(input_size, hidden_size, **kwargs)\n",
        "\n",
        "    self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "  def forward(self, x):\n",
        "    rnn_output, _ = self.rnn(x)\n",
        "    out = self.fc(rnn_output)\n",
        "    return out, rnn_output"
      ],
      "metadata": {
        "id": "tnrJTH1DChRI"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import neurogym as ngym\n",
        "\n",
        "\n",
        "task_name = 'ContextDecisionMaking-v0'\n",
        "kwargs = {'dt': 20, 'timing': {'stimulus': 1500}}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0vni5qzCjmQ",
        "outputId": "5c896a50-321a-4b67-e85b-9580f44f6277"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py:421: UserWarning: \u001b[33mWARN: The `registry.all` method is deprecated. Please use `registry.values` instead.\u001b[0m\n",
            "  logger.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_len = 150\n",
        "batch_size = 24\n",
        "\n",
        "dataset = ngym.Dataset(task_name, env_kwargs=kwargs, batch_size=batch_size, seq_len=seq_len)\n",
        "env = dataset.env\n",
        "\n",
        "inputs, target = dataset()\n",
        "inputs = torch.from_numpy(inputs).type(torch.float)\n",
        "\n",
        "input_size = env.observation_space.shape[0]\n",
        "output_size = env.action_space.n\n",
        "\n",
        "print(inputs.shape)\n",
        "print(target.shape)"
      ],
      "metadata": {
        "id": "2Nf3TDtyCmLP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79fc0c5d-33b3-4a9c-b409-102acb5b5eee"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([150, 24, 7])\n",
            "(150, 24)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:329: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_size = 192\n",
        "\n",
        "net = RNNNet(input_size=input_size, hidden_size=hidden_size, output_size=output_size, dt=env.dt)\n",
        "print(net)\n",
        "\n",
        "def train_model(net, dataset):\n",
        "    optimizer = optim.Adam(net.parameters(), lr = 0.01)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    running_loss = 0\n",
        "    running_acc = 0\n",
        "    start_time = time.time()\n",
        "\n",
        "    for i in range(2000):\n",
        "        inputs, labels = dataset()\n",
        "        inputs = torch.from_numpy(inputs).type(torch.float)\n",
        "        labels = torch.from_numpy(labels.flatten()).type(torch.long)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output, _ = net(inputs)\n",
        "        output = output.view(-1, output_size)\n",
        "        loss = criterion(output, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 99:\n",
        "            running_loss /= 100\n",
        "            print('Step {}, Loss {:0.4f}, Time {:0.1f}s'.format(\n",
        "                i+1, running_loss, time.time() - start_time))\n",
        "            running_loss = 0\n",
        "    return net\n",
        "\n",
        "net = train_model(net, dataset)"
      ],
      "metadata": {
        "id": "8N_iUD8wColv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9e2ec33-46a1-4fd7-b328-4a532bdf1ebd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RNNNet(\n",
            "  (rnn): LeakyRNN(\n",
            "    (input2hidden): Linear(in_features=7, out_features=192, bias=True)\n",
            "    (hidden2hidden): Linear(in_features=192, out_features=192, bias=True)\n",
            "  )\n",
            "  (fc): Linear(in_features=192, out_features=3, bias=True)\n",
            ")\n",
            "Step 100, Loss 26.2008, Time 10.5s\n",
            "Step 200, Loss 0.0777, Time 18.6s\n",
            "Step 300, Loss 0.0392, Time 27.8s\n",
            "Step 400, Loss 0.0302, Time 36.6s\n",
            "Step 500, Loss 0.0266, Time 44.8s\n",
            "Step 600, Loss 0.0249, Time 53.4s\n",
            "Step 700, Loss 0.0247, Time 62.2s\n",
            "Step 800, Loss 0.0234, Time 70.3s\n",
            "Step 900, Loss 0.0229, Time 79.6s\n",
            "Step 1000, Loss 0.0229, Time 88.4s\n",
            "Step 1100, Loss 0.0225, Time 96.8s\n",
            "Step 1200, Loss 0.0223, Time 108.1s\n",
            "Step 1300, Loss 0.0228, Time 117.0s\n",
            "Step 1400, Loss 0.0221, Time 126.0s\n",
            "Step 1500, Loss 0.0220, Time 133.8s\n",
            "Step 1600, Loss 0.0220, Time 142.7s\n",
            "Step 1700, Loss 0.0223, Time 151.6s\n",
            "Step 1800, Loss 0.0220, Time 159.6s\n",
            "Step 1900, Loss 0.0220, Time 169.0s\n",
            "Step 2000, Loss 0.0219, Time 178.1s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env = dataset.env\n",
        "env.reset(no_step=True)\n",
        "\n",
        "perf = 0\n",
        "activity_dict = {}\n",
        "trial_infos = {}\n",
        "\n",
        "num_trial = 200\n",
        "for i in range(num_trial):\n",
        "  trial_info = env.new_trial()\n",
        "  ob, gt = env.ob, env.gt\n",
        "  inputs = torch.from_numpy(ob[:,np.newaxis, :]).type(torch.float)\n",
        "\n",
        "  action_pred, rnn_activity = net(inputs)\n",
        "\n",
        "  action_pred = action_pred.detach().numpy()[:, 0, :]\n",
        "  choice = np.argmax(action_pred[-1, :])\n",
        "  correct = choice == gt[-1]\n",
        "\n",
        "  rnn_activity = rnn_activity[:, 0, :].detach().numpy()\n",
        "  activity_dict[i] = rnn_activity\n",
        "  trial_infos[i] = trial_info\n",
        "  trial_infos[i].update({'choice': choice, 'correct': correct})\n",
        "\n",
        "  if correct:\n",
        "    perf += 1\n",
        "\n",
        "for i in range(10):\n",
        "  print('Trial', i, trial_infos[i])\n",
        "\n",
        "print(f\"Average performance = {np.mean([val['correct'] for val in trial_infos.values()])}\")\n",
        "print(f\"Performance: {perf}/{num_trial}\")\n"
      ],
      "metadata": {
        "id": "1mnIHXrtCq7s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e94b2cac-495e-4340-cc3f-f142299122eb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 0 {'ground_truth': 2, 'other_choice': 1, 'context': 0, 'coh_0': 15, 'coh_1': 15, 'choice': 2, 'correct': True}\n",
            "Trial 1 {'ground_truth': 2, 'other_choice': 1, 'context': 0, 'coh_0': 5, 'coh_1': 5, 'choice': 2, 'correct': True}\n",
            "Trial 2 {'ground_truth': 1, 'other_choice': 1, 'context': 1, 'coh_0': 50, 'coh_1': 15, 'choice': 2, 'correct': False}\n",
            "Trial 3 {'ground_truth': 1, 'other_choice': 1, 'context': 0, 'coh_0': 50, 'coh_1': 5, 'choice': 2, 'correct': False}\n",
            "Trial 4 {'ground_truth': 2, 'other_choice': 1, 'context': 1, 'coh_0': 5, 'coh_1': 5, 'choice': 2, 'correct': True}\n",
            "Trial 5 {'ground_truth': 1, 'other_choice': 1, 'context': 0, 'coh_0': 15, 'coh_1': 50, 'choice': 2, 'correct': False}\n",
            "Trial 6 {'ground_truth': 1, 'other_choice': 2, 'context': 1, 'coh_0': 15, 'coh_1': 15, 'choice': 2, 'correct': False}\n",
            "Trial 7 {'ground_truth': 2, 'other_choice': 2, 'context': 0, 'coh_0': 15, 'coh_1': 50, 'choice': 2, 'correct': True}\n",
            "Trial 8 {'ground_truth': 2, 'other_choice': 2, 'context': 0, 'coh_0': 15, 'coh_1': 5, 'choice': 2, 'correct': True}\n",
            "Trial 9 {'ground_truth': 2, 'other_choice': 1, 'context': 1, 'coh_0': 5, 'coh_1': 50, 'choice': 2, 'correct': True}\n",
            "Average performance = 0.51\n",
            "Performance: 102/200\n"
          ]
        }
      ]
    }
  ]
}